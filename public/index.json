[
{
	"uri": "//localhost:1313/",
	"title": "Amazon S3",
	"tags": [],
	"description": "",
	"content": "Work with Amazon S3 Overall This guide will walk you through setting up a Spring Boot application integrated with AWS S3 from your local machine. You will learn how to create a new Spring Boot project, add AWS SDK dependencies, configure AWS credentials, and set up the AWS SDK in Spring Boot.\nContent Introduction Preparation Setup Application Deploy-to-EC2 Clean up resources "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Welcome to this comprehensive workshop on integrating AWS S3 with a backend application and deploying it on an Amazon EC2 instance. This workshop is designed to guide you through the entire process, from setting up your cloud infrastructure to deploying a fully functional application that interacts with AWS services.\nWhether you are a backend developer with experience looking to expand your cloud skills or someone new to AWS, this workshop will provide you with hands-on experience and practical knowledge. We will cover everything from creating and managing AWS resources to integrating your backend application with S3, making this an essential guide for anyone looking to leverage AWS in their projects.\nBy the end of this workshop, you will have a solid understanding of how to use AWS services to build scalable, secure, and efficient applications\nAmazon EC2 - Amazon Elastic Compute Cloud Amazon EC2 is a cornerstone of cloud computing, providing scalable compute capacity in the cloud. It allows you to deploy virtual servers, known as instances, which can be configured with various operating systems and software to meet your needs. EC2\u0026rsquo;s flexibility makes it an ideal choice for hosting web applications, running distributed systems, or performing big data analytics.\nIn this workshop, we’ll focus on using EC2 to host our backend application. You’ll learn how to launch an EC2 instance, configure it for your application, and take advantage of its auto-scaling and load balancing features to ensure your application is both scalable and resilient.\nAmazon S3 - Amazon Simple Storage Service Amazon S3 is one of the most reliable and cost-effective storage solutions available today. It provides object storage that is accessible from anywhere in the world, allowing you to store and retrieve any amount of data at any time. S3 is designed for 99.999999999% durability, ensuring your data is secure and always available.\nIn this workshop, we will use S3 to manage and store images for our application. You’ll learn how to create an S3 bucket, upload and retrieve files, and manage access permissions. Additionally, we’ll explore features like S3 versioning, lifecycle policies, and security settings to help you manage your data efficiently.\nAWS SDK - Your Toolkit for Building on AWS The AWS SDK is a powerful toolkit that simplifies the process of interacting with AWS services from your application. It provides APIs and libraries for various programming languages, enabling you to perform tasks such as uploading files to S3, launching EC2 instances, and managing AWS resources directly from your code.\nIn this workshop, we will use the AWS SDK for Java to integrate S3 into our backend application. This includes setting up the SDK, writing code to interact with S3, and implementing features like pre-signed URLs for secure uploads. The AWS SDK will empower you to build sophisticated, cloud-enabled applications with ease.\nAWS Secrets Manager AWS Secrets Manager is a service designed to help you securely manage and retrieve credentials, API keys, and other secrets. It eliminates the need to hard-code sensitive information in your application, reducing the risk of exposure and improving security.\nWe will cover how to use Secrets Manager to store and retrieve credentials for accessing AWS services, such as the keys needed to interact with S3. You’ll learn how to integrate Secrets Manager with your application to securely access these credentials, ensuring that your application follows best practices for security.\n"
},
{
	"uri": "//localhost:1313/3-setup-application/3.1-setup-aws-secrets-manager/",
	"title": "Setup AWS Secrets Manager",
	"tags": [],
	"description": "",
	"content": "Hướng dẫn này sẽ hướng dẫn bạn cách thiết lập AWS Secrets Manager để quản lý các thông tin bí m của ứng dụng của bạn.\nBước 1: Tạo Một Bí Mật Trong AWS Secrets Manager Click Store a new secret. Choose Other type of secrets. Enter the following key-value pairs for your AWS credentials and bucket name: Provide a name for your secret (e.g., mySpringBootAppSecrets). { \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34; : [ { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34; : { \u0026#34;AWS\u0026#34; : \u0026#34;arn:aws:iam::017820676824:role/ec2-role-for-s3-and-secret-management\u0026#34; }, \u0026#34;Action\u0026#34; : \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; } ] } Click Next. Evaluate the details for creating a Secrets Manager. You can inspect the sample code provided by AWS for configuring and executing your code to obtain the key. Click the \u0026ldquo;Store\u0026rdquo; button after reviewing "
},
{
	"uri": "//localhost:1313/3-setup-application/3.2-create-springboot-project/",
	"title": "Spring Boot Project Setup",
	"tags": [],
	"description": "",
	"content": "Follow these steps to set up a Spring Boot project integrated with AWS S3 from your local machine.\nStep 1: Create a New Spring Boot Project Use Spring Initializr: Go to Spring Initializr. Set the project details and add the necessary dependencies (Spring Web, Spring Boot DevTools, AWS SDK S3). Click Generate to download the project. Unzip the file and open it in your IDE. Step 2: Add AWS SDK Dependencies If not added during the project setup, add the following dependencies in pom.xml:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.awssdk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;s3\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.awssdk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;auth\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.awssdk\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;regions\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Step 3: Configure AWS Credentials You can set up AWS credentials in your local environment using environment variables or the ~/.aws/credentials file.\nLoad Secrets Dynamically in Code Use the AWS SDK to fetch secrets programmatically. Here’s a streamlined approach .AwsConfig.class. This class will configure the S3 client using credentials retrieved from Secrets Manager: java\npackage com.example.demo.config; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import software.amazon.awssdk.auth.credentials.AwsBasicCredentials; import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider; import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider; import software.amazon.awssdk.regions.Region; import software.amazon.awssdk.services.secretsmanager.SecretsManagerClient; import software.amazon.awssdk.services.s3.S3Client; import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueRequest; import software.amazon.awssdk.services.secretsmanager.model.GetSecretValueResponse; @Configuration public class AwsConfig { @Value(\u0026#34;${aws.secretsmanager.secret.id}\u0026#34;) private String secretId; @Value(\u0026#34;${aws.region}\u0026#34;) private String region; @Bean public SecretsManagerClient secretsManagerClient() { return SecretsManagerClient.builder() .region(Region.of(region)) .build(); } @Bean public S3Client s3Client(SecretsManagerClient secretsManagerClient) { String secretString = getSecret(secretsManagerClient); AwsCredentialsProvider credentialsProvider = StaticCredentialsProvider.create( AwsBasicCredentials.create( extractValue(secretString, \u0026#34;aws.access.key.id\u0026#34;), extractValue(secretString, \u0026#34;aws.secret.access.key\u0026#34;) ) ); return S3Client.builder() .region(Region.of(region)) .credentialsProvider(credentialsProvider) .build(); } private String getSecret(SecretsManagerClient secretsManagerClient) { GetSecretValueRequest request = GetSecretValueRequest.builder() .secretId(secretId) .build(); GetSecretValueResponse response = secretsManagerClient.getSecretValue(request); return response.secretString(); } private String extractValue(String secretString, String key) { String[] entries = secretString.split(\u0026#34;,\u0026#34;); for (String entry : entries) { if (entry.contains(key)) { return entry.split(\u0026#34;:\u0026#34;)[1].replaceAll(\u0026#34;[\\\u0026#34;{}]\u0026#34;, \u0026#34;\u0026#34;).trim(); } } throw new RuntimeException(\u0026#34;Key not found in secret string\u0026#34;); } } S3Service.class This class will use the S3 client to upload files to an S3 bucket:\npackage com.example.demo.service; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Service; import software.amazon.awssdk.core.sync.RequestBody; import software.amazon.awssdk.services.s3.S3Client; import software.amazon.awssdk.services.s3.model.PutObjectRequest; import java.io.ByteArrayInputStream; @Service public class S3Service { private final S3Client s3Client; @Value(\u0026#34;${s3.bucket.name}\u0026#34;) private String bucketName; public S3Service(S3Client s3Client) { this.s3Client = s3Client; } public void uploadFile(String key, byte[] content) { PutObjectRequest putObjectRequest = PutObjectRequest.builder() .bucket(bucketName) .key(key) .build(); s3Client.putObject(putObjectRequest, RequestBody.fromInputStream(new ByteArrayInputStream(content), content.length)); } } Step 6: Create a REST Controller Create a REST controller to expose an endpoint for file uploads:\npackage com.example.demo.controller; import com.example.demo.service.S3Service; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; @RestController public class FileUploadController { private final S3Service s3Service; public FileUploadController(S3Service s3Service) { this.s3Service = s3Service; } @PostMapping(\u0026#34;/upload\u0026#34;) public String uploadFile(@RequestParam(\u0026#34;key\u0026#34;) String key, @RequestParam(\u0026#34;file\u0026#34;) byte[] file) { s3Service.uploadFile(key, file); return \u0026#34;File uploaded successfully!\u0026#34;; } } Step 7: Test API Locally with Postman Start your Spring Boot application by running the main class or using your IDE’s run configuration. Use a tool like Postman or curl to send a POST request: Method: POST URL: http://localhost:8080/upload Body: Select form-data and add the following fields: key: Your file key (e.g., test.txt) file: Choose a file to upload curl -F \u0026#34;file=@path/to/your/file\u0026#34; http://localhost:8080/upload Click Send and verify the response: \u0026ldquo;File uploaded successfully!\u0026rdquo;. Verify Upload: Check your S3 bucket via the AWS Management Console to ensure the file has been uploaded successfully. Verify the response URL to ensure it points to the correct file in S3. "
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "Preparing the infrastructure for AWS S3 Integration",
	"content": "Preparation In this section, we will prepare the necessary infrastructure on AWS. This involves setting up a Virtual Private Cloud (VPC) and launching an EC2 instance that will serve as the host for our backend application. Additionally, we will create an S3 bucket for storing images and configure the required IAM roles and users to secure and manage access to these resources.\nContent 2.1 Creating IAM Role An IAM Role is essential for granting your EC2 instance permissions to interact with other AWS services, such as S3. This role will be associated with the EC2 instance, enabling it to upload, retrieve, and delete files in your S3 bucket. We will create a role with the necessary policies and attach it to our EC2 instance.\n2.2 Create IAM User An IAM User will be created to allow programmatic access to AWS services. This user will have specific permissions that limit access to only the resources required for this workshop, following the principle of least privilege. We will generate access keys for this user, which will be used in the backend application to interact with AWS services securely.\n2.3 Create EC2 Instance Next, we will launch an EC2 Instance that will host our backend application. This involves selecting the appropriate Amazon Machine Image (AMI), configuring security groups, and attaching the IAM role we created earlier. We will also install the necessary software, such as Java and Spring Boot, to run our application.\n2.4 Create S3 Bucket An S3 Bucket will be created to store the images that our application will manage. We will configure the bucket with the appropriate permissions, enabling the backend application to upload, retrieve, and delete images. Additionally, we will explore advanced S3 features, such as bucket policies, encryption, and versioning, to ensure our data is secure and compliant with best practices.\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-createiamrole/",
	"title": "Create IAM Role",
	"tags": [],
	"description": "",
	"content": "Creating IAM Role In this section, we will walk through the process of creating an IAM (Identity and Access Management) role that will be used to grant permissions to our EC2 instance for interacting with AWS S3. IAM roles are crucial for securely managing access to AWS resources.\nStep 1: Sign in to AWS Management Console Go to the AWS Management Console. Sign in using your AWS account credentials. Step 2: Navigate to IAM Service In the AWS Management Console, type \u0026ldquo;IAM\u0026rdquo; into the search bar or navigate to Services \u0026gt; IAM to open the IAM dashboard. Step 3: Create a New Role In the IAM dashboard, select Roles from the left-hand menu. Click the Create role button. Step 4: Select Trusted Entity Type Choose AWS service as the trusted entity type. For the use case, select EC2. This allows EC2 instances to assume the role. Step 5: Attach Policies Click the Next: Permissions button. On the permissions page, you need to attach policies that grant permissions to access S3. You can choose an existing policy like AmazonS3FullAccess or create a custom policy if specific permissions are required. AmazonS3FullAccess: Grants full access to all S3 buckets. Custom Policy: If you prefer fine-grained control, click on Create policy and define your custom permissions using the JSON editor or the visual editor. Step 6: Review and Name the Role Click the Next: Tags button to add tags to the role (optional). Click the Next: Review button. Enter a name for the role in the Role name field. For example, EC2-S3-Role. Click the Create role button to create the IAM role. Step 7: Attach Policies After successfully creating an IAM role, you may need to attach an inline policy to further customize the permissions associated with the role. Inline policies are policies that are embedded directly into a single IAM role, group, or user. You need to attach policies that grant permissions to access S3 and Secrets Manager. You can choose existing policies or create a custom policy.\nAmazonS3FullAccess: Grants full access to all S3 buckets. SecretsManagerReadOnly: Grants read-only access to Secrets Manager secrets. Here’s an example of a custom policy JSON that grants specific S3 and Secrets Manager actions: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;CombinedPermissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:secretsmanager:us-east-1:017820676824:secret:upload-image-to-s3-secret-8UsdOW\u0026#34;, \u0026#34;arn:aws:s3:::your-bucket-name\u0026#34;, \u0026#34;arn:aws:s3:::your-bucket-name/*\u0026#34; ] } ] } "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-create-iam-user/",
	"title": "Create IAM User",
	"tags": [],
	"description": "Detailed steps for creating an IAM user in AWS.",
	"content": "Creating an IAM User In this step, we will proceed to create IAM Role. In this IAM Role, the policy AmazonSSMManagedInstanceCore will be assigned, this is the policy that allows the EC2 server to communicate with the Session Manager.\nStep 1: Access IAM Service In the AWS Management Console, type \u0026ldquo;IAM\u0026rdquo; into the search bar or navigate to Services \u0026gt; IAM to open the IAM dashboard. Step 2: Start Creating a New User In the IAM dashboard, select Users from the left-hand menu. Click the Add user button to begin the user creation process. Enter a user name. Then click Next button Click Create user button "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.3-create-ec2/",
	"title": "Creating an EC2 Instance",
	"tags": [],
	"description": "Step-by-step guide to creating and configuring an EC2 instance in AWS.",
	"content": "Creating an EC2 Instance Amazon EC2 (Elastic Compute Cloud) allows you to run virtual servers in the cloud. This guide will walk you through the steps to launch and configure an EC2 instance.\nStep 1: Navigate to EC2 Service In the AWS Management Console, search for \u0026ldquo;EC2\u0026rdquo; in the search bar or navigate to Services \u0026gt; EC2 to open the EC2 dashboard. Step 2: Launch an Instance In the EC2 dashboard, click the Launch Instance button to start the instance creation process. Enter a name for EC2 Instance Step 3: Choose an Amazon Machine Image (AMI) Select an AMI (Amazon Machine Image) for your instance. This image provides the operating system and software configuration for your instance. You can choose from a variety of AMIs, including Amazon Linux, Ubuntu, Windows, etc. Look for AMIs marked as \u0026ldquo;Free Tier Eligible\u0026rdquo; to take advantage of the free tier benefits, which offer limited usage at no cost. Step 4: Choose an Instance Type Select the instance type that matches your requirements. Instance types vary by CPU, memory, storage, and networking capacity. For general purposes, you might choose an instance type like t2.micro (eligible for the free tier). Create a new key pair or use an existing one. This key pair is used to securely connect to your instance via SSH. Step 5: Configure Instance Configure the instance details, including the number of instances, network, and subnet settings.\nSet additional options if needed, such as IAM roles or monitoring.\nStep 6: Add Storage Add storage volumes to your instance if required. The default settings usually include a root volume. You can attach additional EBS (Elastic Block Store) volumes as needed. Step 8: Add Tags (Optional) Add tags to your instance to help organize and manage it. Tags are key-value pairs that can be used for cost tracking, automation, and identification. Step 9: Review and Launch Review your instance configuration to ensure everything is correct. Click Launch to start the instance creation process. You will be prompted to select an existing key pair or create a new one. This key pair is used to securely connect to your instance via SSH. Step 11: Access Your Instance Once the instance is launched, go back to the EC2 dashboard and select Instances to view your new instance.\nUse the public IP address or DNS name of the instance to connect to it.\nFor Linux instances, connect using SSH: ssh -i \u0026quot;your-key.pem\u0026quot; ec2-user@your-instance-public-dns For Windows instances, use RDP (Remote Desktop Protocol) with the credentials provided. Conclusion You have successfully created and launched an EC2 instance. You can now configure and use your instance as needed for your application or development tasks.\nFor further details and advanced configurations, refer to the AWS EC2 Documentation.\n"
},
{
	"uri": "//localhost:1313/3-setup-application/",
	"title": "Setup Application",
	"tags": [],
	"description": "",
	"content": "Content 3.1. 3.1-Setup AWS Secrets Manager 3.2. Create-SpringBoot-Project\n"
},
{
	"uri": "//localhost:1313/5-cleanup/",
	"title": "Clean up resources",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance Go to EC2 service management console\nClick Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm. Go to IAM service management console\nClick Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role. Click Users. Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user. Delete S3 bucket Access System Manager - Session Manager service management console.\nClick the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save. Go to S3 service management console\nClick on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit. After deleting all objects in the bucket, click Delete\nEnter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket. "
},
{
	"uri": "//localhost:1313/4-deploy-to-ec2/",
	"title": "Deploy Application EC2",
	"tags": [],
	"description": "",
	"content": "Deploy Spring Boot Application to EC2 and Test API In this guide, you will learn how to deploy a Spring Boot application to an EC2 instance and test the API.\nStep 1: Launch and Configure EC2 Instance 1.1 Launch an EC2 Instance 1.2 Connect to Your EC2 Instance Open Terminal on your local machine. Change Permissions of your key pair file: chmod 400 /path/to/your-key-pair.pem Connect to EC2 Instance: ssh -i /path/to/your-key-pair.pem ec2-user@your-ec2-public-dns Step 2: Set Up Environment on EC1 2.1 Install Java and Maven Install Maven: sudo yum install java-11-openjdk -y For Ubuntu, use: sudo apt-get update sudo apt-get install openjdk-11-jdk -y Install Maven: sudo yum install maven -y For Ubuntu, use: sudo apt-get install maven -y 2.2 Transfer Your Spring Boot Application Create a JAR File of your Spring Boot application: mvn clean package Transfer JAR File to your EC2 instance: scp -i /path/to/your-key-pair.pem /path/to/your-spring-boot-app.jar ec2-user@your-ec2-public-dns:/home/ec2-user/ Step 3: Run Your Spring Boot Application 3.1 Navigate to the Directory Log in to your EC2 instance and navigate to the directory where you transferred the JAR file: cd /home/ec2-user/ 3.2 Run the JAR File Run the JAR file: java -jar your-spring-boot-app.jar You should see logs indicating that the application has started and is listening on the specified port. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.4-create-s3-bucket/",
	"title": "Creating an S3 Bucket",
	"tags": [],
	"description": "Step-by-step guide to creating and configuring an S3 bucket in AWS.",
	"content": "Creating an S3 Bucket Amazon S3 (Simple Storage Service) is a scalable storage service that allows you to store and retrieve any amount of data from anywhere. This guide will walk you through the steps to create and configure an S3 bucket.\nStep 1: Navigate to S3 Service In the AWS Management Console, search for \u0026ldquo;S3\u0026rdquo; in the search bar or navigate to Services \u0026gt; S3 to open the S3 dashboard. Step 2: Create a New Bucket In the S3 dashboard, click the Create bucket button to start the bucket creation process.\nStep 3: Configure Bucket Settings Bucket Name: Enter a unique name for your bucket. Bucket names must be globally unique across all AWS regions.\nRegion: Choose the AWS region where you want to create the bucket. Consider selecting a region close to your target users to reduce latency.\nStep 4: Configure Bucket Options Object Ownership:\nChoose between ACLs disabled (recommended) or ACLs enabled based on your use case. Disabling ACLs simplifies permissions by using only bucket policies for access control. Block Public Access Settings:\nBy default, Amazon S3 blocks public access to your bucket. Keep this setting enabled to protect your data unless you specifically need to make your bucket publicly accessible. Bucket Versioning:\nEnable versioning to keep multiple versions of an object in the same bucket. This is useful for data backups and recovery. Tags:\nAdd tags to your bucket to organize and manage it more effectively. Tags are key-value pairs that can be used for cost tracking, automation, and identification. Default Encryption:\nEnable default encryption to automatically encrypt all objects stored in the bucket. You can choose between AWS-managed keys (SSE-S3) or AWS Key Management Service (SSE-KMS) for encryption. Advanced Settings:\nConfigure logging, object lock, and other advanced settings if needed. These options are generally used for more specialized use cases. Step 5: Review and Create Review all the configurations you\u0026rsquo;ve set for the bucket to ensure they meet your requirements.\nClick Create bucket to finalize the creation.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]